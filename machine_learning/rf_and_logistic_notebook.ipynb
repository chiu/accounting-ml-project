{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in integrated file:  3388\n",
      "Number of records in Services-packaged software industrial category:  3388\n",
      "Accuracy on training data:  0.9902597402597403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[rea: double, label: double, features: vector]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['SPARK_HOME'] = '/home/envmodules/lib/spark-2.2.0-bin-hadoop2.7/'\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder.appName('733').getOrCreate()\n",
    "\n",
    "# Using the integrated file to start working on\n",
    "integrated_df = spark.read.parquet('/user/vcs/annual_integrated_dataset_with_labels_ibes_fix_v2.parquet').cache()\n",
    "\n",
    "\n",
    "def find_performance_metrics(res, model_used):\n",
    "    res = res.withColumn('correct', res.label == res.prediction)\n",
    "\n",
    "    num_rows = res.count()\n",
    "    accuracy = res.filter(res.label == res.prediction).count() / res.count()\n",
    "\n",
    "    # positive class (misstatements)\n",
    "    true_positives_df = res.filter(res.prediction == 1.0).filter(res.label == 1.0)\n",
    "    ground_truth_positives_df = res.filter(res.label == 1.0)\n",
    "    misstatement_recall = true_positives_df.count() / ground_truth_positives_df.count()\n",
    "\n",
    "    new_all_predicted_positive_df = res.filter(res.prediction == 1.0)\n",
    "    misstatement_precision = true_positives_df.count() / new_all_predicted_positive_df.count()\n",
    "\n",
    "    # negative class (non misstatements)\n",
    "    true_negative_df = res.filter(res.prediction == 0.0).filter(res.label == 0.0)\n",
    "    ground_truth_negative_df = res.filter(res.label == 0.0)\n",
    "    non_misstatement_recall = true_negative_df.count() / ground_truth_negative_df.count()\n",
    "\n",
    "    new_all_predicted_negative_df = res.filter(res.prediction == 0.0)\n",
    "    non_misstatement_precision = true_negative_df.count() / new_all_predicted_negative_df.count()\n",
    "\n",
    "    d = {'model_used': model_used, 'accuracy': accuracy, \\\n",
    "         'misstatement_precision': misstatement_precision, \\\n",
    "         'misstatement_recall': misstatement_recall}\n",
    "    df = pd.DataFrame(data=d, index=[0])\n",
    "    file_name = \"performance_metrics\" + \"\".join(model_used.split()) + \".csv\"\n",
    "    df.to_csv(file_name, encoding='utf-8')\n",
    "\n",
    "    print(\"Using {}\".format(model_used))\n",
    "    print('accuracy is {}'.format(accuracy))\n",
    "    print('misstatement_precision is {}, misstatement recall is {}'.format(misstatement_precision, misstatement_recall))\n",
    "    print('non_misstatement_precision is {}, non_misstatement recall is {}'.format(non_misstatement_precision,\n",
    "                                                                                   non_misstatement_recall))\n",
    "\n",
    "\n",
    "# Downsampling:\n",
    "misstated_df = integrated_df.filter(integrated_df.label == 1.0)\n",
    "misstated_count = misstated_df.count()\n",
    "non_misstated_df = integrated_df.filter(integrated_df.label == 0.0).limit(misstated_count)\n",
    "integrated_df = misstated_df.union(non_misstated_df).cache()\n",
    "\n",
    "# Using nullcounts to filter columns to keep\n",
    "nullcounts = integrated_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in integrated_df.columns])\n",
    "nc = list(nullcounts.first())\n",
    "\n",
    "# Services-packaged software category selection (from EDA)\n",
    "services_prepacked_software = integrated_df  # .filter(integrated_df.sic == '7372')\n",
    "print('Total records in integrated file: ', integrated_df.count())\n",
    "print('Number of records in Services-packaged software industrial category: ', services_prepacked_software.count())\n",
    "\n",
    "# Reusing preprocessing steps implemented by Vincent\n",
    "# filling nulls and nones with zeroes.\n",
    "some_dict = {}\n",
    "for x in services_prepacked_software.columns:\n",
    "    some_dict[x] = 0\n",
    "\n",
    "nwdf = services_prepacked_software.fillna(some_dict)\n",
    "\n",
    "good_columns = []\n",
    "for i in range(0, len(nc)):\n",
    "    if nc[i] == 0:\n",
    "        good_columns.append(i)\n",
    "\n",
    "great_columns = [nwdf.columns[i] for i in good_columns]\n",
    "great_columns.append('rea')\n",
    "nwdf = nwdf.fillna(some_dict)\n",
    "\n",
    "# dropping all string columns\n",
    "non_string_columns = [k for (k, v) in nwdf.dtypes if v != 'string']\n",
    "nwdf_no_strings = nwdf.select(*non_string_columns)\n",
    "feature_columns = [item for item in nwdf_no_strings.columns if item not in ['rea', 'features', 'label', 'rea_label']]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "final_df = assembler.transform(nwdf_no_strings)\n",
    "final_final_df = final_df.drop(*feature_columns).cache()\n",
    "\n",
    "# String indexing not required\n",
    "stringIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexed\")\n",
    "si_model = stringIndexer.fit(final_final_df)\n",
    "td = si_model.transform(final_final_df)\n",
    "\n",
    "# Evaluators\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "eval = BinaryClassificationEvaluator()\n",
    "\n",
    "# RandomForest classifier\n",
    "rf = RandomForestClassifier(numTrees=100, maxDepth=16, labelCol=\"indexed\", seed=42)\n",
    "model = rf.fit(td)\n",
    "result = model.transform(final_final_df)\n",
    "print('Accuracy on training data: ', evaluator.evaluate(result))\n",
    "\n",
    "# Train test split for model evaluation\n",
    "train, test = final_final_df.randomSplit([0.7, 0.3], seed=12345)\n",
    "train.cache()\n",
    "test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3388"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_final_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForest model on training set. \n",
      " Model parameters: {Param(parent='RandomForestClassifier_43fe9cefe089525d2408', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 16, Param(parent='RandomForestClassifier_43fe9cefe089525d2408', name='numTrees', doc='Number of trees to train (>= 1).'): 100, Param(parent='RandomForestClassifier_43fe9cefe089525d2408', name='seed', doc='random seed.'): 42, Param(parent='RandomForestClassifier_43fe9cefe089525d2408', name='labelCol', doc='label column name.'): 'label'}\n",
      "Accuracy on test set:  0.8317214700193424\n",
      "Area under ROC curve:  0.9129208749480402\n",
      "Using random forest\n",
      "accuracy is 0.8317214700193424\n",
      "misstatement_precision is 0.8044692737430168, misstatement recall is 0.8622754491017964\n",
      "non_misstatement_precision is 0.8611670020120724, non_misstatement recall is 0.8030018761726079\n"
     ]
    }
   ],
   "source": [
    "# ---------------\n",
    "# Random Forest:\n",
    "# ---------------\n",
    "\n",
    "rf = RandomForestClassifier(numTrees=100, maxDepth=16, labelCol=\"label\", seed=42)\n",
    "print('Training RandomForest model on training set. \\n Model parameters: {}'.format(rf._paramMap))\n",
    "trained_model = rf.fit(train)\n",
    "res = trained_model.transform(test)\n",
    "metrics = MulticlassMetrics(res.select(['label', 'prediction']).rdd)\n",
    "print('Accuracy on test set: ', evaluator.evaluate(res))\n",
    "print('Area under ROC curve: ', eval.evaluate(res))\n",
    "find_performance_metrics(res, \"random forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogisticRegression model on training set.\n",
      "Accuracy on test set:  0.7156673114119922\n",
      "Area under ROC curve:  0.79554586886265\n",
      "Using logistic regression\n",
      "accuracy is 0.7156673114119922\n",
      "misstatement_precision is 0.6757215619694398, misstatement recall is 0.7944111776447106\n",
      "non_misstatement_precision is 0.7685393258426966, non_misstatement recall is 0.6416510318949343\n",
      "objectiveHistory:\n",
      "0.693054780889867\n",
      "0.6832815629719761\n",
      "0.6665432637919997\n",
      "0.6566143166735775\n",
      "0.6523768157731895\n",
      "0.6340166196417919\n",
      "0.6038257285703489\n",
      "0.5999231777516096\n",
      "0.5987003389535266\n",
      "0.5983496107895722\n",
      "0.5973352637699861\n",
      "0.5957638683527767\n",
      "0.5936116465903114\n",
      "0.5930597269206699\n",
      "0.5926519647087672\n",
      "0.5924898476386136\n",
      "0.5922993564142169\n",
      "0.591472652293314\n",
      "0.5911468466977239\n",
      "0.5910659212121527\n",
      "0.591032521735034\n",
      "0.5910105861790761\n",
      "0.5909677331851787\n",
      "0.5909506214723904\n",
      "0.5909388641217875\n",
      "0.5909379351749218\n",
      "0.5909357218358776\n",
      "0.5909217636609192\n",
      "0.590919500921314\n",
      "0.5909174359066834\n",
      "0.5909109936801681\n",
      "0.5908988636347207\n",
      "0.5908775879661616\n",
      "0.5908542289277597\n",
      "0.5908033468643755\n",
      "0.5906387508223588\n",
      "0.5904852399333489\n",
      "0.5904698171952887\n",
      "0.5903270756094321\n",
      "0.5902029297072995\n",
      "0.5900966844280391\n",
      "0.589936234791341\n",
      "0.5897043529781452\n",
      "0.5892667108525109\n",
      "0.588923152515053\n",
      "0.5885601976617096\n",
      "0.5884063137809091\n",
      "0.5883408409945589\n",
      "0.5883378785862792\n",
      "0.5883043442977738\n",
      "0.5883013939659267\n",
      "0.5882948080671669\n",
      "0.5882881355894313\n",
      "0.588281747755421\n",
      "0.5882717704364628\n",
      "0.588252486577856\n",
      "0.5882498991486889\n",
      "0.5882484300240169\n",
      "0.5882478949302746\n",
      "0.5882471736621285\n",
      "0.5882471195917448\n",
      "0.5882464554140738\n",
      "0.5882460504974946\n",
      "0.5882458874740207\n",
      "0.5882457780701641\n",
      "0.5882456610897885\n",
      "0.5882453824946097\n",
      "0.5882452742850927\n",
      "0.58824517476934\n",
      "0.588245096943396\n",
      "0.5882450566319678\n",
      "0.5882450537807973\n",
      "0.5882449846596184\n",
      "0.5882449671998015\n",
      "0.5882449564350969\n",
      "0.5882449270072785\n",
      "0.5882449061859558\n",
      "0.5882449002073915\n",
      "0.5882448961242425\n",
      "0.5882448917769386\n",
      "0.5882448893399571\n",
      "0.5882448863817307\n",
      "0.5882448845242124\n",
      "0.5882448842811787\n",
      "0.5882448840676288\n",
      "0.5882448837119325\n",
      "+--------------------+--------------------+\n",
      "|                 FPR|                 TPR|\n",
      "+--------------------+--------------------+\n",
      "|                 0.0|                 0.0|\n",
      "|                 0.0|0.022632020117351215|\n",
      "|8.613264427217916E-4| 0.04442581726739313|\n",
      "|0.001722652885443...| 0.06370494551550712|\n",
      "|0.003445305770887...| 0.08130762782900251|\n",
      "|0.004306632213608958| 0.10058675607711651|\n",
      "|0.004306632213608958| 0.11986588432523052|\n",
      "|0.006029285099052541|  0.1383067896060352|\n",
      "|0.009474590869939707| 0.15423302598491198|\n",
      "|0.012058570198105082| 0.17183570829840739|\n",
      "|0.014642549526270457| 0.18943839061190276|\n",
      "| 0.01808785529715762| 0.20536462699077954|\n",
      "|0.019810508182601206|  0.2179379715004191|\n",
      "|0.024117140396210164|  0.2338642078792959|\n",
      "|0.024978466838931956| 0.25230511316010057|\n",
      "| 0.02756244616709733| 0.26906957250628666|\n",
      "|0.031007751937984496| 0.28667225481978204|\n",
      "|0.034453057708871665| 0.30259849119865884|\n",
      "| 0.03789836347975883| 0.31852472757753564|\n",
      "| 0.04392764857881137|  0.3319362950544845|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "areaUnderROC: 0.803939575747993\n",
      "best threshold is:0.48720314106527324\n",
      "For Logistic regression:\n",
      "Accuracy on test set:  0.7127659574468085\n",
      "Area under ROC curve:  0.7955421240071452\n",
      "Using logistic regression with best threshold\n",
      "accuracy is 0.7127659574468085\n",
      "misstatement_precision is 0.6619047619047619, misstatement recall is 0.8323353293413174\n",
      "non_misstatement_precision is 0.7920792079207921, non_misstatement recall is 0.600375234521576\n",
      "   index feature_column  lr_coeff  abs_lr_coeff\n",
      "0    238           rank  0.766605      0.766605\n",
      "1    234        dvpsp_f -0.319786      0.319786\n",
      "2      9           amgw  0.190248      0.190248\n",
      "3    241         auopic  0.164014      0.164014\n",
      "4     67            gwo -0.125949      0.125949\n"
     ]
    }
   ],
   "source": [
    "# ---------------\n",
    "# Logistic regression:\n",
    "# ---------------\n",
    "print('Training LogisticRegression model on training set.')\n",
    "logistic = LogisticRegression(regParam=0.1, labelCol=\"label\")  # , thresholds = [0.2, 0.5])\n",
    "trained_model = logistic.fit(train)\n",
    "res = trained_model.transform(test)\n",
    "metrics = MulticlassMetrics(res.select(['label', 'prediction']).rdd)\n",
    "print('Accuracy on test set: ', evaluator.evaluate(res))\n",
    "print('Area under ROC curve: ', eval.evaluate(res))\n",
    "find_performance_metrics(res, \"logistic regression\")\n",
    "\n",
    "# Extract the summary from the returned LogisticRegressionModel instance trained\n",
    "# in the earlier example\n",
    "trainingSummary = trained_model.summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "trainingSummary.roc.show()\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "# Set the model threshold to maximize F-Measure\n",
    "fMeasure = trainingSummary.fMeasureByThreshold\n",
    "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head()\n",
    "bestThreshold = fMeasure.where(fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']).select('threshold').head()[\n",
    "    'threshold']\n",
    "logistic.setThreshold(bestThreshold)\n",
    "print('best threshold is:' + str(bestThreshold))\n",
    "\n",
    "print(\"For Logistic regression:\")\n",
    "trained_model = logistic.fit(train)\n",
    "res = trained_model.transform(test)\n",
    "metrics = MulticlassMetrics(res.select(['label', 'prediction']).rdd)\n",
    "print('Accuracy on test set: ', evaluator.evaluate(res))\n",
    "print('Area under ROC curve: ', eval.evaluate(res))\n",
    "# find_performance_metrics(res, \"logistic regression\")\n",
    "find_performance_metrics(res, \"logistic regression with best threshold\")\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {'lr_coeff': trained_model.coefficients,\n",
    "     'feature_column': feature_columns,\n",
    "     })\n",
    "\n",
    "df['abs_lr_coeff'] = df['lr_coeff'].abs()\n",
    "df = df = df.sort_values('abs_lr_coeff', ascending=False).reset_index()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Code for making use of validation set for parameter tuning\n",
    "train, test = final_final_df.randomSplit([0.9, 0.1], seed=12345)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
    "# TrainValidationSplit will try all combinations of values and determine best model using\n",
    "# the evaluator.\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.regParam, [0.2, 0.15, 0.1, 0.01]) \\\n",
    "    .addGrid(lr.threshold, [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 1.0])\\\n",
    "    .build()\n",
    "\n",
    "# A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "tvs = TrainValidationSplit(estimator=lr,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                           evaluator=BinaryClassificationEvaluator(),\n",
    "                           # 80% of the data will be used for training, 20% for validation.\n",
    "                           trainRatio=0.8)\n",
    "\n",
    "# Run TrainValidationSplit, and choose the best set of parameters.\n",
    "model = tvs.fit(train)\n",
    "\n",
    "# Make predictions on test data. model is the model with combination of parameters\n",
    "# that performed best.\n",
    "res = model.transform(test)\n",
    "find_performance_metrics(res, 'logistic_with_validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# For RandomForest\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(rf.numTrees, [50, 100, 150, 200]) \\\n",
    "    .addGrid(rf.maxDepth, [4, 8, 12, 16, 18, 20])\\\n",
    "    .build()\n",
    "    \n",
    "tvs = TrainValidationSplit(estimator=rf,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                           evaluator=BinaryClassificationEvaluator(),\n",
    "                           # 80% of the data will be used for training, 20% for validation.\n",
    "                           trainRatio=0.8)\n",
    "model = tvs.fit(train)\n",
    "res = model.transform(test)\n",
    "find_performance_metrics(res, 'rf_with_validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
